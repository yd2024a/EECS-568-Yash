{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f043f84",
   "metadata": {},
   "source": [
    "# University of Michigan, NA/EECS 568, ROB 530 \n",
    "# Mobile Robotics: Methods & Algorithms, Winter 2024\n",
    "\n",
    "## Homework 1 $-$ Estimation & Filtering\n",
    "\n",
    "- **See the course Canvas for syllabus, due dates, and homework and grading policies.**\n",
    "- This course utilizes an autograder to evaluate homework. For each of the five problems, carefully read the submission instructions and complete the TODOs in the corresponding Python script. Once you have finished coding, upload all scripts to GradeScope for automatic assessment and grading. Please note, the autograder retains only the latest score, not the highest.\n",
    "- For each problem, the autograder will check the **return value** of the function you implement. Additionally, the variables are printed in this notebook for you to review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962e9973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this block to enable autoreload of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a69d9b6",
   "metadata": {},
   "source": [
    "### Problem 1. Probability Basics (20 points)\n",
    "\n",
    "Rick has collected four points (in 2D space); let’s call this set `$r$'. He has computed their mean and (biased) sample covariance to be: \n",
    "$\\begin{equation}    \\nonumber\n",
    "    \\mu_r = \n",
    "    \\begin{bmatrix}\n",
    "        2 \\\\\n",
    "        3\n",
    "    \\end{bmatrix} \\quad  \n",
    "    \\Sigma_{rr} = \n",
    "    \\begin{bmatrix}\n",
    "        5 & 3 \\\\\n",
    "        3 & 7\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}$\n",
    "\n",
    "And Morty has collected six points (from the same 2D space); let’s call it set $m$, finding their mean and (biased) sample covariance to be:\n",
    "\n",
    "$\\begin{equation}    \\nonumber\n",
    "    \\mu_m = \n",
    "    \\begin{bmatrix}\n",
    "        -2 \\\\\n",
    "        2\n",
    "    \\end{bmatrix} \\quad  \n",
    "    \\Sigma_{mm} = \n",
    "    \\begin{bmatrix}\n",
    "        8 & 4 \\\\\n",
    "        4 & 3\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}$\n",
    "\n",
    "#### 1.a (5 points)\n",
    "If Rick computed the sum (over all $r$ points) of $xx^\\top$, what value would he have computed?\n",
    "\n",
    "#### 1.b (5 points)\n",
    "If Morty computed the sum (over all $m$ points) of $xx^\\top$, what value would he have computed?\n",
    " \n",
    "#### 1.c (5 points)\n",
    "We now wish to compute the mean and sample covariance of all ten points (which we will denote $m+r$).\n",
    "What is the mean, $\\mu_{m+r}$?\n",
    "        \n",
    "#### 1.d (5 points)\n",
    "What is the (biased) sample covariance, $\\Sigma_{m+r}$?\n",
    "    \n",
    "*Note: Biased sample covariance has $\\frac{1}{N}$ whereas the unbiased version has $\\frac{1}{N-1}$. The question is making it easier by using the biased formula. See Wikipedia page of Bessel's correction for more explanation.*\n",
    "\n",
    "#### Submission\n",
    "Please fill the **TODO**s in the function contained in **probability_basics.py** and submit the file to gradescope. In this problem, you have the option to either directly report the numerical results (accurate to three decimal places) in the TODO block or implement the formula using `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539dedc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probability_basics import *\n",
    "\n",
    "mu_r = np.array([[2], [3]])\n",
    "sigma_rr = np.array([[5, 3], [3, 7]])\n",
    "mu_m = np.array([[-2], [2]])\n",
    "sigma_mm = np.array([[8, 4], [4, 3]])\n",
    "ans_1a, ans_1b, ans_1c, ans_1d = probability_basics(mu_r, sigma_rr, mu_m, sigma_mm)\n",
    "print('Answer for problem 1a:\\n', ans_1a)\n",
    "print('Answer for problem 1b:\\n', ans_1b)\n",
    "print('Answer for problem 1c:\\n', ans_1c)\n",
    "print('Answer for problem 1d:\\n', ans_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f88715",
   "metadata": {},
   "source": [
    "### Problem 2. Bayes Filter (20 points)\n",
    "\n",
    "#### 2.a (10 points)\n",
    "\n",
    "A robot is equipped with a manipulator to paint an object. Furthermore, the robot has a sensor to detect whether the object is colored or blank. Neither the manipulation unit nor the sensor are   perfect.\n",
    "\n",
    "  From previous experience you know that the robot succeeds in painting a blank object with a probability of\n",
    "  \n",
    "  \\begin{equation*}\n",
    "    p(x_{t+1} = \\text{colored} \\mid x_t = \\text{blank}, u_{t+1} = \\text{paint}) = 0.9,\n",
    "  \\end{equation*}\n",
    "\n",
    "  where $x_{t+1}$ is the state of the object after executing a painting action, $u_{t+1}$ is the   control command, and $x_t$ is the state of the object before performing the action.\n",
    "\n",
    "  The probability that the sensor indicates that the object is colored although it is blank is given by $p(z = \\text{colored} \\mid x = \\text{blank}) = 0.2$, and the probability that the sensor   correctly detects a colored object is given by $p(z = \\text{colored} \\mid x = \\text{colored}) = 0.7$.\n",
    "\n",
    "  Unfortunately, you have no knowledge about the current state of the object (i.e., uniform distribution as prior). However, after the robot performed a painting action the sensor of the robot indicates that the object is colored.\n",
    "\n",
    "  Compute the probability that the object is blank after the robot has performed an action to paint it.\n",
    "\n",
    "#### Submission\n",
    "Please fill the **TODO**s in the function contained in **bayes_filter_a.py** and submit the file to gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad68afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_filter_a import *\n",
    "\n",
    "print('Answer for Problem 2a:\\n', bayes_filter_a(0.9, 0.2, 0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00e4841",
   "metadata": {},
   "source": [
    "#### 2.b (10 points)\n",
    "\n",
    "Consider a robot that resides in a circular world consisting of ten different places that are numbered counterclockwise. The robot is unable to sense the number of its present place directly. However, places 0, 3, and 6 contain a distinct landmark, whereas all other places do not. All three of these landmarks look alike. The likelihood that the robot observes the landmark given it is in one of these places, is 0.8. For all other places, the likelihood of observing the landmark is 0.4.\n",
    "\n",
    "For each place on the circle, we wish to compute the probability that the robot is in that place given that the following sequence of actions is carried out deterministically and the following sequence of observations is obtained: The robot detects a landmark, moves 3 grid cells counterclockwise and detects a landmark, and then moves 4 grid cells counterclockwise and finally perceives no landmark.\n",
    "\n",
    "Implement the circular world described above using a discrete Bayes filter in to numerically arrive at the desired belief.\n",
    "\n",
    "#### Submission\n",
    "Please fill the **TODO**s in the function contained in **bayes_filter_b.py** and submit the file to gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b33396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_filter_b import *\n",
    "\n",
    "belief = bayes_filter_b()\n",
    "print('Answer for Problem 2b:')\n",
    "for i in range(10):\n",
    "    print(\"%6d %18.3f\\n\" % (i, belief[i]))\n",
    "plt.bar(np.arange(0, 10), belief)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a48c86a",
   "metadata": {},
   "source": [
    "### Problem 3. Target Tracking (20 points)\n",
    "\n",
    "A target is moving in a 1D plane. The ownship position is known and fixed at the origin; thus, the target's position at time step $k$ is $x_k$. We have no information on the target's trajectory, and thus we model the motion as a Gaussian random walk with a variance of $ 4~\\mathrm{m}^2 $. Based on previous measurements, we have an initial guess of the target position as $\\mu_0 = 20 ~\\mathrm{m}$ with variance $\\sigma_{0}^2 = 9 ~\\mathrm{m}^2$. We then receive measurement from each of the next two time steps $z_1 = 22 ~\\mathrm{m}$ and $z_2 = 23 ~\\mathrm{m}$. Each with variance 1 $~\\mathrm{m}^2$.\n",
    "\n",
    "Use a Kalman filter to estimate the state of the target at time step 2 ($\\mu _2$ and $\\sigma _2 ^2$).\n",
    "\n",
    "#### Submission\n",
    "Please fill the **TODO**s in the function contained in **target_tracking.py** and submit the file to gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b24fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from target_tracking import *\n",
    "\n",
    "print('Answer for Problem 3:\\n', target_tracking())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d793736",
   "metadata": {},
   "source": [
    "### Problem 4. First-Order Covariance Propagation (20 points)\n",
    "\n",
    "In most SLAM approaches, the noise characteristics of individual observations are linearized, resulting in a Gaussian covariance matrix. In this task, we explore the effects of the error introduced via linearization.\n",
    "\n",
    "Consider a robot sensor that observes range and bearing to nearby landmarks. In this case, the range error is relatively small, but the bearing error is large. We are interested in determining the $(x, y)$ position of the beacon based on observations obtained by the robot at the origin $(0, 0)$. For this problem, the robot does not move.\n",
    "\n",
    "Suppose you obtain a (range, bearing) observation with mean ($10.0$ m, $0$ rad) whose range standard deviation is $0.5$ m, and whose bearing standard deviation is $0.25$ rad. The range and bearing measurements are Gaussian and independent.\n",
    "\n",
    "#### Submission\n",
    "Please fill the **TODO**s in the function contained in **covariance_propagation.py** and submit the file to gradescope. The values in the `result` dict will be evaluated.\n",
    "\n",
    "Due to autograder requirement, code involving `np.random.randn` and `np.random.multivariate_normal` is provided. **DO NOT** change these lines or use other `random` functions in your code, otherwise the autograder will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa69619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from covariance_propagation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410d3565",
   "metadata": {},
   "source": [
    "#### 4.a (4 points)\n",
    "\n",
    "Generate a point cloud representing 10,000 samples from the distribution over the position of the   beacon as measured in\n",
    "  1. the sensor frame, i.e. $(r, \\theta)$ space and\n",
    "  2. the Cartesian $(x, y)$ coordinate frame.\n",
    "  \n",
    "In other words, generate observations of (range, bearing) and project these points into $(x,y)$.   (Hint: use the *numpy.random.randn()* function in python, and recall that you can sample from a univariate Gaussian with mean $\\mu$ and standard deviation $\\sigma$ with $\\mu + \\sigma \\cdot randn$.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dae64bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "result = covariance_propagation()\n",
    "r = result['r']\n",
    "theta = result['theta']\n",
    "x = result['x']\n",
    "y = result['y']\n",
    "\n",
    "print('Answer for Problem 4a:')\n",
    "## Observation in the sensor frame\n",
    "plt.plot(r, theta, '.', markersize=2)\n",
    "plt.axis('equal')\n",
    "plt.grid(True)\n",
    "plt.title('Sensor Frame Point Cloud')\n",
    "plt.xlabel('Range (m)')\n",
    "plt.ylabel('Bearing (rad)')\n",
    "plt.show()\n",
    "\n",
    "## Observation in the Cartesian frame\n",
    "plt.plot(x, y, '.', markersize=2)\n",
    "plt.axis('equal')\n",
    "plt.grid(True)\n",
    "plt.title('Cartesian Frame Point Cloud')\n",
    "plt.xlabel('x (m)')\n",
    "plt.ylabel('y (m)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac6132",
   "metadata": {},
   "source": [
    "#### 4.b (4 points)\n",
    "\n",
    "What is the (linearized) covariance of the beacon position in $(x, y)$ coordinates? In other words,   write the covariance of an observation in $(x,y)$ coordinates in terms of the covariance of the   observation in (range, bearing) coordinates. The transformation is non-linear, so you will need to compute a first-order approximation (Taylor expansion) of the transformation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f428ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "result = covariance_propagation()\n",
    "Jacobian = result['Jacobian']\n",
    "cov_cartesian = result['cov_cartesian']\n",
    "\n",
    "print('Answer for Problem 4b:')\n",
    "print('Jacobian:\\n', Jacobian)\n",
    "print('\\nSigma_cartesian:\\n', cov_cartesian)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f831a67",
   "metadata": {},
   "source": [
    "#### 4.c (4 points)\n",
    "\n",
    "Draw in red the 1-sigma, 2-sigma, and 3-sigma contours of the analytical (linearized) covariance ellipses, super-imposed over the point clouds generated in parts A.i and A.ii. Now overlay in blue the actual covariance ellipses computed using sample-based expressions for the first and second moments. **For you to explore:** Do they agree?  Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbc8872",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "result = covariance_propagation()\n",
    "mu_sensor = result['mu_sensor']\n",
    "cov_sensor = result['cov_sensor']\n",
    "mu_sensor_sample = result['mu_sensor_sample']\n",
    "cov_sensor_sample = result['cov_sensor_sample']\n",
    "mu_cartesian = result['mu_cartesian']\n",
    "cov_cartesian = result['cov_cartesian']\n",
    "mu_cartesian_sample = result['mu_cartesian_sample']\n",
    "cov_cartesian_sample = result['cov_cartesian_sample']\n",
    "\n",
    "print('Answer for Problem 4c:')\n",
    "\n",
    "print('mu_sensor:\\n', mu_sensor)\n",
    "print('\\ncov_sensor:\\n', cov_sensor)\n",
    "print('\\nmu_sensor_sample:\\n', mu_sensor_sample)\n",
    "print('\\ncov_sensor_sample:\\n', cov_sensor_sample)\n",
    "print('\\nmu_cartesian:\\n', mu_cartesian)\n",
    "print('\\ncov_cartesian:\\n', cov_cartesian)\n",
    "print('\\nmu_cartesian_sample:\\n', mu_cartesian_sample)\n",
    "print('\\ncov_cartesian_sample:\\n', cov_cartesian_sample)\n",
    "\n",
    "## Sensor frame\n",
    "\n",
    "plt.plot(r, theta, '.', markersize=2, label='data')\n",
    "plt.axis('equal')\n",
    "plt.grid(True)\n",
    "plt.title('Sensor Frame Point Cloud')\n",
    "plt.xlabel('Range (m)')\n",
    "plt.ylabel('Bearing (rad)')\n",
    "plt.legend()\n",
    "\n",
    "for i in range(3):\n",
    "    # analytical contous in red\n",
    "    draw_ellipse(mu_sensor, cov_sensor, (i+1)**2, 'red')\n",
    "    # sample contous in blue\n",
    "    draw_ellipse(mu_sensor_sample, cov_sensor_sample, (i+1)**2, 'blue')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "## Cartesian frame\n",
    "\n",
    "plt.plot(x, y, '.', markersize=2, label='data')\n",
    "plt.axis('equal')\n",
    "plt.grid(True)\n",
    "plt.title('Cartesian Frame Point Cloud')\n",
    "plt.xlabel('x (m)')\n",
    "plt.ylabel('y (m)')\n",
    "\n",
    "for i in range(3):\n",
    "    # analytical contous in red\n",
    "    draw_ellipse(mu_cartesian, cov_cartesian, (i+1)**2, 'red')    \n",
    "    # sample contous in blue\n",
    "    draw_ellipse(mu_cartesian_sample, cov_cartesian_sample, (i+1)**2, 'blue')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59fbb8f",
   "metadata": {},
   "source": [
    "#### 4.d (4 points)\n",
    "\n",
    "From a purely theoretical perspective, assuming that the underlying process is truly Gaussian, we expect 39.35% of all samples to lie within the 1-sigma contour, 86.47\\% of samples to lie within the 2-sigma contour, and 98.89% to lie within the 3-sigma contour. (These frequencies were computed using the cumulative chi-square distribution for two degrees-of-freedom)\n",
    "\n",
    "Count the samples falling within each (analytical) ellipse. The error of a particular sample $x$, measured in \"units\" of sigma, is known as the Mahalanobis distance, and can be computed as $\\sqrt{(x-\\mu)^\\top\\Sigma^{-1}(x-\\mu)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f37df",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "result = covariance_propagation()\n",
    "count_sensor = result['count_sensor']\n",
    "count_cartesian = result['count_cartesian']\n",
    "N = result['N']\n",
    "\n",
    "print('Answer for Problem 4d:')\n",
    "Gaussian = [0.39, 0.86, 0.99];\n",
    "print(\"         Sensor frame  Cartesian frame  Gaussian\\n\")\n",
    "for k in range(3):\n",
    "    print('%d-sigma%10.2f%16.2f%13.2f\\n' % (k+1, count_sensor[k]/N, count_cartesian[k]/N, Gaussian[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d95a28",
   "metadata": {},
   "source": [
    "**For you to explore:** If the point samples were truly distributed as a Gaussian (clearly, the $(x,y)$ are not), your counts would match the theoretically predicted values. Try varying the noise parameters: under what conditions do the counts come close to matching the theoretically predicted values? What consequences to a state estimation algorithm could these sorts of errors have? Discuss your thoughts on Piazza."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202e2f0e",
   "metadata": {},
   "source": [
    "#### 4.e (4 points)\n",
    "\n",
    "Suppose now that the (range, bearing) measurements are *not independent* but instead jointly correlated under the following three scenarios: \\\n",
    "a) $\\rho_{{r\\theta}}=0.1$, \\\n",
    "b) $\\rho_{r\\theta}=0.5$, and \\\n",
    "c) $\\rho_{r\\theta}=0.9$. \n",
    "\n",
    "Repeat parts 4.a and 4.c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf9b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "result = covariance_propagation()\n",
    "print('Answer for Problem 4e:')\n",
    "for rho in [0.1, 0.5, 0.9]:\n",
    "    r = result['4e'][rho]['r']\n",
    "    theta = result['4e'][rho]['theta']\n",
    "    x = result['4e'][rho]['x']\n",
    "    y = result['4e'][rho]['y']\n",
    "    mu_sensor = result['4e'][rho]['mu_sensor']\n",
    "    cov_sensor = result['4e'][rho]['cov_sensor']\n",
    "    mu_sensor_sample = result['4e'][rho]['mu_sensor_sample']\n",
    "    cov_sensor_sample = result['4e'][rho]['cov_sensor_sample']\n",
    "    mu_cartesian = result['4e'][rho]['mu_cartesian']\n",
    "    cov_cartesian = result['4e'][rho]['cov_cartesian']\n",
    "    mu_cartesian_sample = result['4e'][rho]['mu_cartesian_sample']\n",
    "    cov_cartesian_sample = result['4e'][rho]['cov_cartesian_sample']\n",
    "\n",
    "    # Sensor frame\n",
    "    plt.plot(r, theta, '.', markersize=2, label='data')\n",
    "    plt.axis('equal')\n",
    "    plt.grid(True)\n",
    "    plt.title(r'Sensor Frame Point Cloud with $\\rho$ = %.1f' % rho)\n",
    "    plt.xlabel('Range (m)')\n",
    "    plt.ylabel('Bearing (rad)')\n",
    "    plt.legend()\n",
    "\n",
    "    # plot the ellipses\n",
    "    for i in range(3):\n",
    "        # analytical contous in red\n",
    "        draw_ellipse(mu_sensor, cov_sensor, (i+1)**2, 'red')\n",
    "        # sample contous in blue\n",
    "        draw_ellipse(mu_sensor_sample, cov_sensor_sample, (i+1)**2, 'blue')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Cartesian frame\n",
    "    plt.plot(x, y, '.', markersize=2, label='data')\n",
    "    plt.axis('equal')\n",
    "    plt.grid(True)\n",
    "    plt.title(r'Cartesian Frame Point Cloud with $\\rho$ = %.1f' % rho)\n",
    "    plt.xlabel('x (m)')\n",
    "    plt.ylabel('y (m)')\n",
    "\n",
    "    # plot the ellipses\n",
    "    for i in range(3):\n",
    "        # analytical contous in red\n",
    "        draw_ellipse(mu_cartesian, cov_cartesian, (i+1)**2, 'red')    \n",
    "        # sample contous in blue\n",
    "        draw_ellipse(mu_cartesian_sample, cov_cartesian_sample, (i+1)**2, 'blue')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a4d55c",
   "metadata": {},
   "source": [
    "### Problem 5. Estimation\n",
    "\n",
    "Assume that we want to estimate an unobserved population parameter $\\theta$ on the basis of observations $x$. Let $f$ be the sampling distribution of $x$ so that $f(x|\\theta)$ is the probability of $x$ when the underlying population parameter is $\\theta$. The function $L(\\theta) = f(x|\\theta)$ when viewed as a function of the parameter $\\theta$ is called the likelihood function or just the likelihood.\n",
    "For example, if $x$ follows a Gaussian distribution, we will have $\\theta = (\\mu, \\sigma^2)$ and $$\\mu, \\sigma \\mapsto f(x|\\mu,\\sigma^2) = \\frac{1}{\\sigma \\sqrt{2\\pi}}\\exp(-\\frac{1}{2}\\frac{(x-\\mu)^2}{\\sigma^2})$$ is the likelihood. \n",
    "\n",
    "**Maximum Likelihood Estimator (MLE):** The maximum likelihood method maximizes the likelihood function, leading to the MLE\n",
    "\\begin{equation} \n",
    "    \\nonumber \\hat{\\theta}_{MLE} = \\text{argmax}_\\theta L(\\theta) = \\text{argmax}_\\theta f(x|\\theta).\n",
    "\\end{equation}\n",
    "\n",
    "**Maximum A Posteriori (MAP) Estimator:** In the Bayesian framework, one can place a prior distribution over the parameter, i.e., $g(\\theta)$. Then, the MAP estimator maximizes the posterior probability density function $f(\\theta|x)$ as follows.\n",
    "\\begin{equation}\\nonumber\n",
    "    \\hat{\\theta}_{MAP} = \\text{argmax}_\\theta f(\\theta|x)\n",
    "    = \\text{argmax}_\\theta \\frac{f(x|\\theta)g(\\theta)}{\\int_\\Theta f(x|\\vartheta)g(\\vartheta)d\\vartheta}\n",
    "    = \\text{argmax}_\\theta f(x|\\theta)g(\\theta),\n",
    "\\end{equation}\n",
    "were the last equality is true because the normalization constant in the Bayes' formula is independent of $\\theta$.\n",
    "\n",
    "**Remark 1:**\n",
    "Since $\\log$ is a monotonic function, it is often the case that we use the logarithm of the likelihood or posterior for maximization (or negative of the logarithm for minimization).\n",
    "\n",
    "**Remark 2:**\n",
    "In this case, $x$ is a known noisy measurement of $θ$ and its distribution is $\\mathcal{N}(\\mu_x, \\sigma^2_x).$\n",
    "\n",
    "\n",
    "Now suppose we have a continuous random variable $\\theta \\sim \\mathcal{N}(\\mu,\\sigma^2)$. We wish to infer its mean and variance as we obtain normally distributed measurements sequentially. For the case of a random mean, $\\mu$, and fixed variance, $\\sigma^2$: \n",
    "\n",
    "\n",
    "#### Submission\n",
    "Please fill the **TODO**s in the function contained in **estimation.py** and submit the file to gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86f885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from estimation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240ef4bc",
   "metadata": {},
   "source": [
    "#### 5.a (5 points)\n",
    "\n",
    "You will get 5 points for implementing `Inference` function correctly.\n",
    "\n",
    "Derive formulas to make a Bayesian inference so that we can infer both the mean and the variance. \n",
    "\n",
    "**Hint:** Use Bayes' formula and substitute the Gaussian prior and likelihood in the formula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9ed7b9",
   "metadata": {},
   "source": [
    "#### 5.b (5 points)\n",
    "\n",
    "You will get 5 points for implementing `estimation_MAP` function correctly. Your `estimation_MAP` function will be tested using the accurate version of the `Inference` function. Therefore, you can still proceed with this problem and earn points even if you encounter difficulties with problem 5.a.\n",
    "\n",
    "You are responsible for purchasing a sensor that can measure the range (distance) to an object. \n",
    "Sensor I (\\$100) and II (\\$500) are both used to measure the range to an object. \n",
    "Suppose the measurements are noisy values of the range, $x$, such that $z \\sim \\mathcal{N}(\\mu_z,\\sigma_z^2)$ with variances of 1 (I) and 0.64 (II). The measurements obtained from these sensors can be seen in Table I and II. Parameterize the prior of $x$ with $\\mu = 0$ and $\\sigma ^2 = 1000$. Using the derivations from part B, write a function that takes data as input and solves the inference recursively.\n",
    "\n",
    "#### b.1 \n",
    "Use the sensor data and the function to infer the mean and variance of the normally distributed random variable $x$ conditioned only on $z_1$.\n",
    "\n",
    "#### b.2 \n",
    "Use the sensor data and the function to infer the mean and variance of the normally distributed random variable $x$ conditioned only on $z_2$.\n",
    "\n",
    "**For you to explore:** \n",
    "Why is it that $x$ is more precise (https://en.wikipedia.org/wiki/Precision_(statistics)) when conditioned on $z_1$ even though sensor II is more accurate? which sensor do you recommend to be purchased?\n",
    "\n",
    "Table 1: Sensor I Data\n",
    "    \n",
    "| N   | $Z_1$     |\n",
    "| --- | --------- |\n",
    "| 1   | 10.6715   |\n",
    "| 2   | 8.7925    |\n",
    "| 3   | 10.7172   |\n",
    "| 4   | 11.6302   |\n",
    "| 5   | 10.4889   |\n",
    "| 6   | 11.0347   |\n",
    "| 7   | 10.7269   |\n",
    "| 8   | 9.6966    |\n",
    "| 9   | 10.2939   |\n",
    "| 10  | 9.2127    |\n",
    "\n",
    "Table 2: Sensor II Data\n",
    "    \n",
    "| N   | $Z_2$     |\n",
    "| --- | --------- |\n",
    "| 1   | 10.7107   |\n",
    "| 2   | 9.0823    |\n",
    "| 3   | 9.1449    |\n",
    "| 4   | 9.3524    |\n",
    "| 5   | 10.2602   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69f9652",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_1, variance_1, mean_2, variance_2 = estimation_MAP(Inference)\n",
    "print('Answer for Problem 5b:')\n",
    "print(\"sensor   mean  variance  precision(1/variance)\")\n",
    "print(\"  I%11.3f%8.3f%10.3f\" % (mean_1, variance_1, 1/variance_1))\n",
    "print(\" II%11.3f%8.3f%10.3f\" % (mean_2, variance_2, 1/variance_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38723042",
   "metadata": {},
   "source": [
    "#### 5.c (10 points)\n",
    "\n",
    "\n",
    "You will get 5 points for implementing `KF_update` function correctly, and another 5 points for implementing `estimation_KF` function correctly. Your `estimation_KF` function will be tested using the accurate version of the `KF_update` function. Therefore, you can still proceed with this problem and earn points even if you encounter difficulties with `KF_update` function.\n",
    "\n",
    "Use a Kalman filter class and write a program to solve b.1 and b.2. Compare your results with the MAP estimator. \n",
    "\n",
    "**For you to explore:** What is the conclusion now and why? Discuss your thoughts on Piazza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955c27c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_1, variance_1, mean_2, variance_2 = estimation_KF(KF_update)\n",
    "\n",
    "print('Answer for Problem 5c:')\n",
    "print(\"sensor   mean  variance  precision(1/variance)\")\n",
    "print(\"  I%11.3f%8.3f%10.3f\" % (mean_1, variance_1, 1/variance_1))\n",
    "print(\" II%11.3f%8.3f%10.3f\" % (mean_2, variance_2, 1/variance_2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
